# 游닄 Cuadernos de Procesamiento Digital de Im치genes

Este repositorio contiene cuadernos de Google Colab relacionados con el Procesamiento Digital de Im치genes.

## 游닇 칈ndice de Cuadernos

* [cite_start][**024 - Img Caption.ipynb**](024%20-%20Img%20Caption.ipynb) : Generaci칩n Autom치tica de Descripciones de Im치genes 

---

## 游 024 - Img Caption.ipynb: Generaci칩n Autom치tica de Descripciones de Im치genes

[cite_start]Este cuaderno te gu칤a a trav칠s de la generaci칩n autom치tica de descripciones para im치genes utilizando Modelos de Lenguaje Visual (VLMs). [cite_start]Aprender치s a usar estos modelos para "subtitular" tus im치genes y, lo que es a칰n mejor, 춰en espa침ol!  [cite_start]Al final, tendr치s un sistema funcional que genera estas descripciones autom치ticamente.

### [cite_start]游꿢 Objetivos de Aprendizaje 

Al finalizar este cuaderno, podr치s:

* [cite_start]**Entender c칩mo funcionan los VLMs (Modelos de Lenguaje-Visi칩n):** Comprender치s c칩mo estos modelos combinan lo que "ven" con lo que "entienden" del lenguaje para generar texto.
* [cite_start]**Generar subt칤tulos autom치ticamente:** Explorar치s c칩mo se crean descripciones de im치genes de forma aut칩noma.
* [cite_start]**Implementar un sistema completo:** Armar치s un generador de descripciones de im치genes que funcione en espa침ol.

### [cite_start]游늷 Conceptos Clave 

Para seguir el hilo del cuaderno, ten칠 en cuenta estos conceptos:

* [cite_start]**Image Captioning:** Es el proceso autom치tico de generar texto que describe el contenido visual de una imagen. [cite_start]Imaginate que ten칠s una foto y quer칠s que una computadora le ponga un "subt칤tulo" o una descripci칩n, eso es `Image Captioning`.
* [cite_start]**BLIP (Bootstrap Language-Image Pre-training):** Este es el modelo de IA que se utiliza para el `Image Captioning`. [cite_start]Es un modelo de `transformers` que fue entrenado con much칤simas im치genes y textos, lo que le permite entender la relaci칩n entre lo visual y lo textual.
* [cite_start]**Traducci칩n Autom치tica:** Como el modelo BLIP genera las descripciones en ingl칠s, se usa otro modelo para traducir autom치ticamente esas descripciones al espa침ol. [cite_start]Es como tener un traductor instant치neo para nuestro sistema.

### 丘뙖잺 Instrucciones de Uso

Para ejecutar este cuaderno y probar el sistema de generaci칩n de descripciones, sigue estos pasos:

1.  **Abre el cuaderno en Google Colab:** Haz clic en el enlace "024 - Img Caption.ipynb" en el 칤ndice de arriba, o navega hasta el archivo en tu repositorio de GitHub y selecci칩nalo. Una vez en GitHub, haz clic en el bot칩n "Open in Colab" (o "Abrir en Colab") en la parte superior.

2.  [cite_start]**Instala las dependencias:** Una vez abierto el cuaderno en Colab, busca la celda con el t칤tulo `# @title Instalaci칩n de Dependencias`  [cite_start]y ejec칰tala. [cite_start]Esto instalar치 las librer칤as necesarias como `transformers`, `gradio`, `Pillow`, `accelerate` y `sentencepiece`. [cite_start]Se te indicar치 si debes reiniciar el entorno de ejecuci칩n.

3.  [cite_start]**Importa librer칤as y configura modelos:** Ejecuta la celda con el t칤tulo `# @title Importando Librer칤as y Configuracion de Modelos`. [cite_start]Esto cargar치 los modelos de Inteligencia Artificial que realizan la magia de "leer" la imagen y traducirla. [cite_start]Incluye el `BlipProcessor`, `BlipForConditionalGeneration` y un modelo de traducci칩n de ingl칠s a espa침ol.

4.  [cite_start]**Define la funci칩n `generar_descripcion`:** Ejecuta la celda con el t칤tulo `# @title Funci칩n generar_descripcion`. [cite_start]Esta funci칩n es el coraz칩n del sistema, se encarga de procesar la imagen, generar la descripci칩n en ingl칠s y luego traducirla al espa침ol.

5.  [cite_start]**Inicia la interfaz de usuario:** Finalmente, ejecuta la celda con el t칤tulo `# @title 游깷 Interfaz de Usuario`. [cite_start]Esta celda crear치 una interfaz web simple con Gradio. [cite_start]Una vez ejecutada, ver치s una URL (puede tardar unos segundos en aparecer). [cite_start]Haz clic en esa URL para abrir la interfaz de Gradio en tu navegador y 춰empez치 a probar tu generador de descripciones! 

### [cite_start]游닇 Instrucciones para Usar la Interfaz 

1.  [cite_start]**Sub칤 una imagen:** Us치 el campo de arriba que dice "Sub칤 tu imagen ac치". [cite_start]Pod칠s arrastrar y soltar una foto, o **clickear** para seleccionarla desde tu computadora.
2.  [cite_start]**Generar la descripci칩n:** Una vez que la imagen est치 cargada, **hac칠 clic** en el bot칩n "Generar Descripci칩n".
3.  [cite_start]**Observ치 los resultados:** Vas a ver un cuadro con formato JSON que te va a mostrar la descripci칩n en ingl칠s y la traducci칩n al espa침ol.

### [cite_start]游뱂 Para Pensar un Poco: Reflexiones 

Una vez que hayas probado el sistema, t칩mate un momento para reflexionar sobre lo siguiente:

* 쯈u칠 tan precisas te parecieron las descripciones que gener칩 el modelo? 쯊e sorprendi칩 alguna? 
* 쯈u칠 tipo de detalles capt칩 mejor el modelo en las im치genes? [cite_start]쯏 cu치les no tanto? 
* [cite_start]Si tuvieras que mejorar algo, 쯖칩mo crees que se podr칤a mejorar la calidad de las traducciones al espa침ol? 
* Pensando en el mundo real, 쯤u칠 aplicaciones pr치cticas le ves a esta tecnolog칤a? 쮻칩nde la usar칤as? 

---

## 游끥 Conclusi칩n

춰Felicitaciones! 游꿀 Has llegado al final de esta clase y has armado tu propio sistema de generaci칩n autom치tica de descripciones de im치genes. Hoy aprendiste c칩mo los Modelos de Lenguaje-Visi칩n (VLMs) pueden "entender" y "describir" el contenido de una imagen, y c칩mo puedes usar la traducci칩n autom치tica para que esos resultados est칠n en espa침ol.

Viste c칩mo se combinan diferentes modelos (uno para el captioning, otro para la traducci칩n) y c칩mo `Gradio` te permite armar una interfaz de usuario muy r치pido.

---

### 游녤 Pr칩ximos Pasos 

La Inteligencia Artificial es un campo que crece muy r치pido. Aqu칤 te dejamos algunas ideas para que sigas investigando:

* [cite_start]**Experiment치 con otros modelos:** En Hugging Face ten칠s un mont칩n de modelos de `Image Captioning` y `Traducci칩n` para probar. [cite_start]쮿ay alguno que funcione mejor? 
* **Mejor치 la traducci칩n:** A veces las traducciones autom치ticas no son perfectas. 쮺칩mo podr칤as incorporar m치s contexto o incluso usar modelos de traducci칩n m치s avanzados? 
* [cite_start]**Agreg치 funcionalidades:** 쯈u칠 tal si tu sistema pudiera identificar objetos espec칤ficos en la imagen o responder preguntas sobre ella?  [cite_start]Investig치 sobre `Object Detection` o `Visual Question Answering`.
* **Optimiz치 el rendimiento:** Si quer칠s que tu modelo sea m치s r치pido, podr칤as investigar t칠cnicas de cuantizaci칩n o _distillation_.